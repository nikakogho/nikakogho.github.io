* AI safety lead at [[US AI Safety Institute]]
* Founder and head of [[Alignment Research Center]]
* Founded the direction of [[Eliciting Latent Knowledge]]
* Trained [[Evan Hubinger]] during his time in [[MIRI]]
* [LinkedIn](https://www.linkedin.com/in/paul-christiano-5089211bb)
* His post about possible scenario of AGI destroying humanity [here](https://www.alignmentforum.org/posts/AyNHoTWWAJ5eb99ji/another-outer-alignment-failure-story)
* His views on doom [here](https://www.lesswrong.com/posts/xWMqsvHapP3nwdSW8/my-views-on-doom)

![paul_christiano_views_on_doom.png](paul_christiano_views_on_doom.png)
