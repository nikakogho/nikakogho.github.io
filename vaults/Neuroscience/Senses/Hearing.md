Hairs inside \[\[Ear]] turn vibration into \[\[Spike|neural spikes]]
Born deaf -> hard to learn when fixed
Got deaf late -> instantly heard well with implant

## Otoacoustic Emissions

Sound comes back from ear
Can be used to measure cochlear amplifier’s strength

Damaged ear can get too much => tinnitus or a kind of sound the person doesn't hear but others do

## Prosody

Specific brain area figures out emotional tone of speech (like “alright” as hype of winning vs “alright” on being made to wash dishes)

## Main Pathway

Many parallel pathways exist, main one is:
0\. Sound in outside world as air vibration

1. Air enters outer ear and pushes on eardrum
2. Middle ear ossicles move in response and push on the oval window
3. Fluid moves in response in cochlea and this innervates hair cells
4. Hair cells \[\[Synapse]] on **spiral ganglions** and send them \[\[Glutamate]]
5. Axons of spiral ganglions make up the \[\[Cranial Nerves|vestibulocochlear nerve (Cranial Nerve VIII)]]
6. These axons synapse on **dorsal cochlear nucleus** and **ventral cochlear nucleus** in \[\[Medulla oblongata]]
7. Cells in ventral cochlear nucleus send axons to **superior olive**
8. Superior olive ascends to **lateral lemniscus** and innervates **inferior colliculus** of \[\[Midbrain]]
9. Inferior colliculus sends axons to MGN of \[\[Thalamus]]
10. MGN projects to \[\[Auditory Cortex]]
    ![Pasted\_image\_20250402101126.png](pasted_image_20250402101126.png)

## Notable pathways

* Inferior colliculus also sends axons to \[\[Cerebellum]] and to **superior colliculus**, which mixes visual and audio input
* Feedback: auditory cortex sends data to MGN, \[\[Brain Stem]] neurons send data back to outer hair cells
* Cochlear nucleus gets input from ear on same side. Other auditory systems take both ear inputs => if you are deaf in one ear the damage is somewhere on the way to cochlear nucleus

## Sound Intensity and Frequency Encoding

Intensity is encoded by active neuron amount and firing rates => louder means more activation
Louder also increases frequency range of each hair cell

We feel loudness by how many neurons spike and how fast

## Tonotopy

Base of cochlea for higher frequencies, apex for lower
![Pasted\_image\_20250408141634.png](pasted_image_20250408141634.png)

## Phase locking

Response always on same part of phase, but might skip some cycles
Works up to 5kHz because above that neurons can no longer spike fast enough
![Pasted\_image\_20250408141924.png](pasted_image_20250408141924.png)

### Volley Principle

AKA **volley theory** - group of neurons all phase-locked creating a bigger phase-locked activity
![Pasted\_image\_20250408142216.png](pasted_image_20250408142216.png)

## Sound localization

### Horizontal

Horizontal location is by **Interaural Time Differences (ITDs)**, basically when each ear spikes, their time difference is horizontal location difference. This doesn't work well above 2kHz for repeated sounds because new cycle already starts before sound wave goes from one year to next.
But high frequency noise creates **sound shadow**, which sensitive neurons can pick up on for horizontal localization
![Pasted\_image\_20250408144452.png](pasted_image_20250408144452.png)
Together these 2 are **duplex theory of sound localization**

Neurons deeper inside hearing system take input from both ears (binaural) and they encode for different interaural time delays by using different length axons such that for each neuron the signals from both ears arrive at the same time during a specific interaural delay
![Pasted\_image\_20250408145706.png](pasted_image_20250408145706.png)
Bird brains use this exact method.
Mammals might be using this + synaptic inhibition

### Vertical and forward/backward

To tell if it's forward or backward we need extra data and we get that from outer ear's (pinna's) shape. These are called **monaural spectral cues**, which work differently based on elevation and front or back of incoming noise. That's why pinna has such shape
![Pasted\_image\_20250408150028.png](pasted_image_20250408150028.png)

Owls don't have pinna so instead their ears are at different vertical points on their heads so they can use interaural time delay for vertical location too
