Like a recurrent [[Neural Network]] but with [[Attention|self-attention]] baked in

Introduced in a cool paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
