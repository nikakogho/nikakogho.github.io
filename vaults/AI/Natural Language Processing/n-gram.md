Sequence of n items (characters, words, tokens...) in text

n = 1 -> unigram
n = 2 -> bigram
n = 3 -> trigram

[[Large Language Models]] count how many n-grams of given n we find and use it to determine probability of predicting next word in text