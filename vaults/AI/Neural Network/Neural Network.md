Layers, linear equations, sometimes [[ReLu]] or [[Sigmoid Activation]]

Input layer, hidden layers, output layer

Can do [[Backpropagation]] using [[Gradient Descent]] or other way to learn by result

In **binary classification*** for [[Supervised Learning]] a neural network is made of [[Perceptron]] neurons

Good video for this from [Harvard](https://www.youtube.com/watch?v=J1QD9hLDEDY)
